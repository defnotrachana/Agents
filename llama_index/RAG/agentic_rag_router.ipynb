{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (1.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting llama-index\n",
      "  Using cached llama_index-0.12.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.8 (from llama-index)\n",
      "  Using cached llama_index_core-0.12.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.3.12-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.57.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.2.15)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2024.12.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2.9.2)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.16.0)\n",
      "Collecting llama-cloud>=0.1.5 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Using cached llama_cloud-0.1.7-py3-none-any.whl.metadata (860 bytes)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: click in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: certifi<2025.0.0,>=2024.7.4 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-cloud>=0.1.5->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: anyio in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama-index) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.8->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.8->llama-index) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from click->nltk>3.8.1->llama-index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.26.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.16.0)\n",
      "Using cached llama_index-0.12.8-py3-none-any.whl (6.8 kB)\n",
      "Using cached llama_index_agent_openai-0.4.1-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Using cached llama_index_core-0.12.8-py3-none-any.whl (1.6 MB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\n",
      "Using cached llama_index_llms_openai-0.3.12-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.1-py3-none-any.whl (5.8 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.1-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached llama_cloud-0.1.7-py3-none-any.whl (242 kB)\n",
      "Using cached llama_parse-0.5.18-py3-none-any.whl (15 kB)\n",
      "Using cached openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, requests, nltk, openai, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.2\n",
      "    Uninstalling openai-1.57.2:\n",
      "      Successfully uninstalled openai-1.57.2\n",
      "Successfully installed dirtyjson-1.0.8 llama-cloud-0.1.7 llama-index-0.12.8 llama-index-agent-openai-0.4.1 llama-index-cli-0.4.0 llama-index-core-0.12.8 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-llms-openai-0.3.12 llama-index-multi-modal-llms-openai-0.4.1 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.1 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.18 nltk-3.9.1 openai-1.58.1 requests-2.32.3 striprtf-0.0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.4 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-llms-openai) (0.12.8)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-llms-openai) (1.58.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.12.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->llama-index-llms-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.26.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (24.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-openai in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-embeddings-openai) (0.12.8)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-embeddings-openai) (1.58.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2024.12.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.26.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\rachanaa\\.virtualenvs\\23102024-0vmrazk-\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-openai) (24.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install --upgrade python-dotenv\n",
    "! py -m pip install --upgrade llama-index\n",
    "! py -m pip install --upgrade llama-index-llms-openai\n",
    "! py -m pip install --upgrade llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "openai_api_key = \"sk-proj-g1ZDvCjAWM0A\"\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 2\n",
      "file_name: metagpt.pdf\n",
      "file_path: metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-12-25\n",
      "last_modified_date: 2024-12-25\n",
      "\n",
      "Preprint\n",
      "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
      "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
      "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
      "(e.g., Product Manager, Architect, Engineer, etc.).\n",
      "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
      "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
      "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
      "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
      "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
      "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
      "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
      "lunch?” – Bob (Architect).\n",
      "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
      "we adopt meta-programming1 as ”programming to program”, in contrast to the broader fields of meta\n",
      "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
      "2006; Finn et al., 2017).\n",
      "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
      "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
      "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
      "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
      "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
      "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
      "ing how agent-based techniques can enhance meta-programming.\n",
      "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
      "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
      "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
      "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
      "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
      "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
      "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
      "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
      "We summarize our contributions as follows:\n",
      "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "node_metadata = nodes[1].get_content(metadata_mode=True)\n",
    "print(str(node_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define LLM and Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embedding = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sumary Index and Vector Index over the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SummaryIndex` and `VectorStoreIndex` are specialized index types for handling different data storage and retrieval mechanisms, both designed to work with data that's been preprocessed into \"nodes\".  \n",
    "  \n",
    "`SummaryIndex` is designed to handle the summary or aggregation of documents. nodes are the collection of text data.  \n",
    "  \n",
    "`VectorStoreIndex` is designed to store and manage the vector embeddings that are used for tasks like semantic search or similarity search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Query Engines and Set Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `summary_index` and `vector_index` are converted into `query engines` - which is responsible to processing queries and generating responses based on the data (nodes) that have been indexed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode = \"tree_summarize\",\n",
    "    use_async = True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: This choice indicates that the document is useful for summarization questions related to MetaGPT..\n",
      "\u001b[0mThe document introduces MetaGPT, a meta-programming framework that enhances multi-agent systems based on Large Language Models (LLMs) through Standardized Operating Procedures (SOPs). It incorporates role specialization, workflow management, and efficient communication mechanisms to improve problem-solving capabilities. MetaGPT involves agents like Product Managers, Architects, Project Managers, Engineers, and QA Engineers, each with specific roles and responsibilities. Through a collaborative process, MetaGPT generates structured outputs like technical specifications, code files, and unit tests to streamline software development tasks. The document details the development process of a software application called the \"Drawing App\" using MetaGPT, covering requirements gathering, UI design, system architecture, implementation approach, testing, and task allocation. It highlights the use of Python libraries like Tkinter and Pillow, along with unit testing, and discusses MetaGPT's performance in generating executable code compared to other models. The document also addresses challenges, ethical concerns, and experiments conducted to evaluate MetaGPT's performance, emphasizing its structured approach in transforming abstract requirements into detailed software designs efficiently.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context from the MetaGPT paper, which would likely include information on how agents share information with other agents..\n",
      "\u001b[0mAgents share information with other agents by utilizing a shared message pool where they can publish structured messages and subscribe to relevant messages based on their profiles. This shared message pool allows all agents to exchange messages directly, enabling them to access messages from other entities transparently. By storing information in this global message pool, agents can retrieve required information without the need to inquire about other agents individually, thus enhancing communication efficiency.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Ablation study results are specific context from the MetaGPT paper, making choice 2 the most relevant..\n",
      "\u001b[0mThe ablation study results show that MetaGPT effectively addresses challenges related to context utilization, code hallucinations, and information overload in software development. By accurately interpreting natural language descriptions, maintaining information validity, and focusing on granular tasks, MetaGPT mitigates issues such as incomplete code implementation, missing dependencies, and undiscovered bugs. Additionally, the use of a global message pool and a subscription mechanism helps manage information overload by streamlining communication and filtering out irrelevant contexts, thereby enhancing the relevance and utility of information in software development.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "23102024-0vMrazk-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
