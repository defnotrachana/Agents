{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (1.55.12)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (3.11.11)\n",
      "Requirement already satisfied: click in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (8.1.8)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (0.27.2)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (8.5.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (3.1.5)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.55.3 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (1.58.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (2.10.4)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (0.8.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from litellm) (0.19.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx<0.28.0,>=0.23.0->litellm) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx<0.28.0,>=0.23.0->litellm) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx<0.28.0,>=0.23.0->litellm) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx<0.28.0,>=0.23.0->litellm) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx<0.28.0,>=0.23.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.22.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from openai>=1.55.3->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from openai>=1.55.3->litellm) (0.8.2)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from openai>=1.55.3->litellm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from openai>=1.55.3->litellm) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from tiktoken>=0.7.0->litellm) (2.27.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from aiohttp->litellm) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from aiohttp->litellm) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from aiohttp->litellm) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from aiohttp->litellm) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from aiohttp->litellm) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from aiohttp->litellm) (1.18.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from click->litellm) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from tokenizers->litellm) (0.23.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (1.26.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.0.12)\n",
      "Requirement already satisfied: qdrant-client in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from qdrant-client) (1.68.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from qdrant-client) (1.68.1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
      "Requirement already satisfied: numpy>=1.26 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from qdrant-client) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from qdrant-client) (2.10.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from qdrant-client) (1.26.20)\n",
      "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.6.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client) (308)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (4.12.2)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
      "Requirement already satisfied: duckduckgo_search in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (7.0.2)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from duckduckgo_search) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.9.2 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from duckduckgo_search) (0.9.2)\n",
      "Requirement already satisfied: lxml>=5.3.0 in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from duckduckgo_search) (5.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rachanaa\\.virtualenvs\\openai--jxyl4ov\\lib\\site-packages (from click>=8.1.7->duckduckgo_search) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! py -m pip install litellm\n",
    "! py -m pip install qdrant-client\n",
    "! py -m pip install -U duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import PyPDF2\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Ensure CA certificates for secure connection\n",
    "os.environ['CURL_CA_BUNDLE'] = 'C:/Users/RACHANAA/Downloads/cacert.pem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import PyPDF2\n",
    "def read_pdfs_from_folder(folder_path):\n",
    "    pdf_list = []\n",
    "    \n",
    "    # Loop through all the files from a folder\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # open each pdf file\n",
    "            with open(pdf_path, \"rb\") as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                content = \"\"\n",
    "                \n",
    "                # read each page's content and append it to a string\n",
    "                for page_num in range(len(reader.pages)):\n",
    "                    page = reader.pages[page_num]\n",
    "                    content += page.extract_text()\n",
    "                \n",
    "                # add the pdf content to the list\n",
    "                pdf_list.append({\"content\": content, \"filename\": filename})\n",
    "                \n",
    "    return pdf_list\n",
    "\n",
    "folder_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Web URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import requests\n",
    "\n",
    "def fetch_url_content(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetches the content of a web page given its URL.\n",
    "    Args:\n",
    "        url (str): The URL of the web page to fetch.\n",
    "    Returns:\n",
    "        Optional[str]: The content of the web page as a string, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    prefix_url: str = \"https://r.jina.ai/\"\n",
    "    full_url: str = prefix_url + url # concatenate the prefix URL with the main url \n",
    "    try:\n",
    "        response = requests.get(full_url) # perform a GET request\n",
    "        if response.status_code == 200: # check if the request was successful\n",
    "            return response.content.decode('utf-8') # return the content of the response\n",
    "        else:\n",
    "            print(f\"Failed to fetch content. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred while fetching the content: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content retrieved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Repleace the url with the specific endpoint that you want to fetch\n",
    "url: str = \"https://www.freechildrenstories.com/gemma\"\n",
    "content: Optional[str] = fetch_url_content(url)\n",
    "\n",
    "if content is not None:\n",
    "    print(\"Content retrieved successfully.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the content from URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "metadatas = []\n",
    "texts.append(content)\n",
    "metadatas.append({\"url\": url})\n",
    "\n",
    "assert len(metadatas) == len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.freechildrenstories.com/gemma'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_size = 150\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    chunk_size=token_size,\n",
    "    chunk_overlap=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove all the newline characters\n",
    "    text = text.replace(\"\\n\", \" \").replace('\\r', ' ')\n",
    "    \n",
    "    #replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # strip leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 229\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_splitter.split_text(content)\n",
    "print(f\"Total Chunks: {len(text_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import requests\n",
    "def get_embeddings(texts, model=\"text-embedding-3-small\", api_key = os.getenv(\"OPENAI_API_KEY\")):\n",
    "    # define the api url\n",
    "    url = \"https://api.openai.com/v1/embeddings\"\n",
    "    \n",
    "    # Prepare headers with the API key\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    # Prepare the data payload\n",
    "    data = {\n",
    "        \"input\": texts,\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "    # send a post request to the openai api \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    if response.status_code == 200: # check if the request was successful\n",
    "        return response.json()['data']\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings_objects = get_embeddings(text_chunks, api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "assert len(embeddings_objects) == len(text_chunks), \"Number of embeddings does not match number of text chunks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [obj[\"embedding\"] for obj in embeddings_objects]\n",
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "# Create in-memory Qdrant instance\n",
    "qdrant = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'agentic_rag_base' created successfully in Qdrant Cloud.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHANAA\\AppData\\Local\\Temp\\ipykernel_11436\\2434367515.py:4: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant.recreate_collection(\n"
     ]
    }
   ],
   "source": [
    "VECTOR_SIZE = 1536\n",
    "collection_name = \"agentic_rag_base\"\n",
    "# Create collection to store books\n",
    "qdrant.recreate_collection(\n",
    "    collection_name= collection_name,\n",
    "    vectors_config = VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "print(f\"Collection '{collection_name}' created successfully in Qdrant Cloud.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "payload = []\n",
    "for id, text in enumerate(text_chunks):\n",
    "    ids.append(id)\n",
    "    payload.append({\"url\":url, \"content\": text})\n",
    "\n",
    "len(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant.upload_collection(\n",
    "    collection_name = collection_name,\n",
    "    vectors = embeddings, \n",
    "    payload = payload,\n",
    "    ids = ids,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=229)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.count(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(text: str, top_k: int):\n",
    "    query_embedding = get_embeddings(text, api_key=openai_api_key)[0][\"embedding\"]\n",
    "    \n",
    "    search_result = qdrant.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector = query_embedding,\n",
    "        query_filter = None,\n",
    "        limit = top_k\n",
    "    )\n",
    "    return search_result\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.payload['content'] for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompts\n",
    "1. First prompt will check to see if the retrieved context can answer the user question\n",
    "2. Second prompt will get the context and question and generate the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_system_prompt = \"\"\"\n",
    "Your job is to decide if a given question can be answered with a given context. \n",
    "If context can answer the question, return 1. \n",
    "If not, return 0.\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert for answering questions. Answer the questions according only to the question that is being given\n",
    "If the question cannot be answered using the context, simply say I don't know. Please do not make stuff up.\n",
    "Your answer MUST be informative, concise, and action driven. Your answer must be in markdown.\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Question: {question}\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What was the riddle?\"\n",
    "results = search(question, top_k = 3)\n",
    "context = format_docs(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = completion(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"content\": decision_system_prompt.format(context=context),\"role\": \"system\"}, {\"content\": user_prompt.format(question=question),\"role\": \"user\"}],\n",
    "    max_tokens=500,\n",
    "    # format=\"json\"\n",
    "    \n",
    ")\n",
    "has_answer = response.choices[0].message.content\n",
    "has_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from duckduckgo_search import DDGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does Gemma do in the story?\n",
      "Context can answer the question\n",
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Gemma settles down and reflects on a riddle while expressing her frustration about not knowing certain things. She paces and recites what she remembers of the riddle, indicating her desire to solve it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_search_results(results):\n",
    "    return \"\\n\\n\".join(doc[\"body\"] for doc in results)\n",
    "    \n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "if has_answer == '1':\n",
    "    print(\"Context can answer the question\")\n",
    "    response = completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"content\": system_prompt.format(context=context),\"role\": \"system\"}, {\"content\": user_prompt.format(question=question),\"role\": \"user\"}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    print(\"Answer:\")\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "else:\n",
    "    print(\"Context is NOT relevant. Searching online...\")\n",
    "    results = DDGS().text(question, max_results=5)\n",
    "    context = format_search_results(results)\n",
    "    print(\"Found online sources. Generating the response...\")\n",
    "    response = completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"content\": system_prompt.format(context=context),\"role\": \"system\"}, {\"content\": user_prompt.format(question=question),\"role\": \"user\"}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    print(\"Answer:\")\n",
    "    display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai--Jxyl4OV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
